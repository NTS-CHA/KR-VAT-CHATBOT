from fastapi import FastAPI, Request
from fastapi.responses import FileResponse, JSONResponse, Response
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from openai import OpenAI
from typing import Literal
import os, time, json, requests
from dotenv import load_dotenv
from pathlib import Path
import re

load_dotenv()
app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# ì˜ì–´ ì¡°ë¬¸ëª… ë§¤í•‘ í…Œì´ë¸”
LAW_NAME_MAP_EN = {
    "ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì œ26ì¡° ì œ1í•­": "VAT Act Article 26 (1)",
    "ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì œ10ì¡°": "VAT Act Article 10",
    "ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì œ60ì¡°": "VAT Act Article 60",
    "ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì‹œí–‰ë ¹ ì œ30ì¡° ì œ2í•­": "Enforcement Decree Article 30 (2)",
}





class Query(BaseModel):
    question: str
    lang: Literal["ko", "en"] = "ko"
    law_id: str = "ë¶€ê°€ê°€ì¹˜ì„¸ë²•"


def parse_law_text_to_dict(law_text: str) -> dict:
    lines = law_text.splitlines()
    current_key = ""
    mapping = {}
    for line in lines:
        if re.match(r"\[.*ë²•.*\]", line.strip()):
            current_key = line.strip("[]").strip()
            mapping[current_key] = ""
        elif current_key:
            mapping[current_key] += line + "\n"
    return mapping



def self_rate_answer(question: str, answer: str) -> int:
    try:
        completion = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a legal accuracy evaluator. Rate how confident you are in the accuracy of this answer (0-100). Respond only like: Confidence: 87"},
                {"role": "user", "content": f"Question: {question}\nAnswer: {answer}"}
            ],
            temperature=0.2,
            timeout=10
        )
        line = completion.choices[0].message.content.strip()
        if "Confidence" in line:
            return int("".join(filter(str.isdigit, line)))
    except Exception:
        pass
    return 0


def extract_law_references_and_omission(answer: str) -> tuple[list[str], dict]:
    bracketed = re.findall(r"\[(.*?)\]", answer)
    # loose = re.findall(r"ë¶€ê°€ê°€ì¹˜ì„¸ë²•\s?ì œ\d+ì¡°", answer)
    law_tags = re.findall(r"ë¶€ê°€ê°€ì¹˜ì„¸ë²•\s?ì œ\d+ì¡°", answer)
    case_tags = re.findall(r"\d{4}ë‘\d+", answer)
    refs = list(set(r.strip() for r in bracketed + law_tags + case_tags))

    total = len(set(law_tags))
    present = sum(1 for ref in set(law_tags) if any(ref in b for b in bracketed))
    missing = total - present
    stats = {
        "total_refs": total,
        "bracketed": present,
        "omitted": missing,
        "omission_rate": round(missing / total * 100, 1) if total else 0
    }
    return refs, stats


def extract_law_reference_mapping(answer: str, refs: list[str], lang="ko") -> dict[str, str]:
    refs = list(set(r.strip() for r in refs))
    law_refs = [r for r in refs if "ë²•" in r or "ì‹œí–‰" in r or re.match(r"\d{4}ë‘\d+", r)]
    sys_msg = (
                "Extract 1 sentence from the answer that clearly includes this law reference. Output in Korean."
                if lang == "ko"
                else
                "Extract 1 sentence from the answer that clearly includes this law reference. Output in English."
            )
    mapping = {}
    for ref in law_refs:
        try:
            completion = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": sys_msg},
                    {"role": "user", "content": f"Answer: {answer}\nReference: {ref}"}
                ],
                temperature=0.1,
                timeout=10
            )
            mapping[ref] = completion.choices[0].message.content.strip()
        except Exception:
            mapping[ref] = "(ë§¤í•‘ ì‹¤íŒ¨)"
    return mapping


def summarize_reference_tags(refs: list[str], lang="ko") -> dict:
    summaries = {}
    total_time = 0
    count = 0
    refs = list(set(ref.strip() for ref in refs))  # âœ… ì¤‘ë³µ ì œê±° ë° ê³µë°± ì œê±°

    for tag in refs:
        if not tag.strip():
            continue
        start = time.time()

        try:
            # âœ… ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ì§€ì •
            sys_msg = (
                "Summarize what this Korean legal tag refers to in 1 sentence. Output in Korean."
                if lang == "ko"
                else
                "Summarize what this Korean legal tag refers to in 1 sentence. Output in English."
            )

            completion = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": sys_msg},
                    {"role": "user", "content": tag}
                ],
                temperature=0.2,
                timeout=15
            )

            summary = completion.choices[0].message.content.strip()
            elapsed = time.time() - start
            print(f"â±ï¸ íƒœê·¸ '{tag}' ìš”ì•½ ì‹œê°„: {elapsed:.2f}ì´ˆ")
            total_time += elapsed
            count += 1

            if elapsed > 7:
                summaries[tag] = "(ìš”ì•½ ìƒëµ - ì‹œê°„ ì´ˆê³¼)"
                continue

            summaries[tag] = summary

        except Exception:
            summaries[tag] = "ìš”ì•½ ì‹¤íŒ¨"

    if count:
        print(f"ğŸ“Š í‰ê·  ìš”ì•½ ì‹œê°„: {total_time/count:.2f}ì´ˆ ({count}ê°œ íƒœê·¸)")
    return summaries


def auto_infer_references(question: str, answer: str) -> list[str]:
    try:
        completion = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ì‚¬ìš©ì ì§ˆë¬¸ê³¼ GPTì˜ ì‘ë‹µì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ëœ í•œêµ­ ì„¸ë²• ì¡°ë¬¸ ì´ë¦„ì„ ìµœëŒ€ 3ê°œê¹Œì§€ ì¶”ì¶œí•´ì¤˜. ë°˜ë“œì‹œ [ì¡°ë¬¸ëª…] í˜•íƒœë¡œ ëŒ€ê´„í˜¸ë¡œ ê°ì‹¸ì„œ ëª©ë¡ìœ¼ë¡œ ì¶œë ¥í•´. ì˜ˆ: [ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì œ25ì¡°]"},
                {"role": "user", "content": f"ì§ˆë¬¸: {question}\nì‘ë‹µ: {answer}"}
            ],
            temperature=0.2,
            timeout=15
        )
        return re.findall(r"\\[(.*?)\\]", completion.choices[0].message.content)
    except Exception as e:
        print(f"âš ï¸ íƒœê·¸ ìë™ì¶”ë¡  ì‹¤íŒ¨: {e}")
        return []
 
def ask_with_law_context(question: str, law_text: str, precedents: str = "", lang: str = "ko") -> tuple[str, list[str], dict, dict]:
    system_prompt = (
        "You are a Korean VAT law expert and certified tax consultant.\n"
        "Use the following law mapping exactly as shown:\n"
        "- ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì œ26ì¡° ì œ1í•­ â†’ [VAT Act Article 26 (1)]\n"
        "- ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì‹œí–‰ë ¹ ì œ30ì¡° ì œ2í•­ â†’ [Enforcement Decree Article 30 (2)]\n"
        "- 2010ë‘26101 â†’ [Precedent 2010Du26101]\n"
        "Never use [VAT Act Article 10].\n"
        "When explaining input tax deduction for passenger vehicles, always refer to Article 26 (1).\n"
        "Wrap each law or case in square brackets like [VAT Act Article 26 (1)].\n"
      
        "Always reference specific law articles like [VAT Act Article 25] or [Precedent 2010Du1234].\n"
        "Understand and explain legal structure: articles, subsections, exceptions.\n"
        "Cross-reference Enforcement Decree and precedents.\n"
        "Always wrap referenced laws in square brackets like [VAT Act Article 10]."
        if lang == "en" else
        "ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ì„¸ë²• ì „ë¬¸ê°€ì´ì ê³ ë“±ì„¸ë¬´ì‚¬ì…ë‹ˆë‹¤.\n"
        "ëª¨ë“  ë‹µë³€ì— ë°˜ë“œì‹œ ë²•ë ¹ ì¡°ë¬¸ì´ë‚˜ íŒë¡€ë¥¼ ê·¼ê±°ë¡œ ì œì‹œí•˜ì‹­ì‹œì˜¤.\n"
        "ì˜ˆ: [ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì œ25ì¡°], [ì‹œí–‰ë ¹ ì œ5ì¡° ì œ2í•­], [2012ë‘5678].\n"
        "ë²•ë ¹ì˜ ì¡°ë¬¸ êµ¬ì¡°, ì˜ˆì™¸, ì ìš©ë²”ìœ„ë¥¼ êµ¬ë¶„í•´ í•´ì„í•˜ì‹­ì‹œì˜¤.\n"
        "ëª¨ë“  ì¸ìš© ë²•ë ¹ ì¡°ë¬¸ì€ ë°˜ë“œì‹œ [ë¶€ê°€ê°€ì¹˜ì„¸ë²• ì œ10ì¡°] í˜•ì‹ì²˜ëŸ¼ ëŒ€ê´„í˜¸ë¡œ ê°ì‹¸ ëª…ì‹œí•˜ì‹­ì‹œì˜¤."
)

    law_dict = parse_law_text_to_dict(law_text)
    content = f"Relevant Law:\n{law_text}\n\nPrecedents:\n{precedents}\n\nQuestion:\n{question}"
    try:
        response = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": content}
            ],
            temperature=0.3
        )
        answer = response.choices[0].message.content.strip()
        refs, omission_stats = extract_law_references_and_omission(answer)
        if not refs:
            refs = auto_infer_references(question, answer)

        tag_law_map = {}
        for tag in refs:
            tag_ko = tag
            if lang == "en":
                tag_ko = next((k for k, v in LAW_NAME_MAP_EN.items() if v == tag), tag)
            tag_law_map[tag] = law_dict.get(tag_ko, "")

        summaries = summarize_reference_tags(refs, lang)
        mappings = extract_law_reference_mapping(answer, refs, lang)
        return answer, refs, summaries, mappings
    except Exception as e:
        return {
            "answer": f"âŒ GPT ì˜¤ë¥˜: {str(e)}",
            "references": [],
            "summaries": {},
            "mappings": {},
            "confidence": 0
        }

def fetch_combined_laws(law_ids: list[str], output: str = "XML") -> str:
    combined = ""
    for law_id in law_ids:
        params = {
            "OC": os.getenv("LAW_OC_ID", "elapse64"),
            "target": "law",
            "type": output,
            "ID": law_id
        }
        try:
            r = requests.get("https://www.law.go.kr/DRF/lawService.do", params=params, timeout=10)
            if r.status_code == 200:
                combined += f"\n\n[{law_id}]\n" + r.text
        except:
            continue
    return combined if combined else "(âš ï¸ ë²•ë ¹ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨)"

def fetch_precedents_by_query(keyword: str, max_count: int = 2) -> str:
    search_url = "https://www.law.go.kr/DRF/lawSearch.do"
    params = {
        "OC": os.getenv("LAW_OC_ID", "elapse64"),
        "target": "prec",
        "query": keyword,
        "display": max_count,
        "type": "XML"
    }
    try:
        r = requests.get(search_url, params=params, timeout=10)
        if r.status_code != 200:
            return "(âš ï¸ íŒë¡€ ê²€ìƒ‰ ì‹¤íŒ¨)"

        from xml.etree import ElementTree as ET
        root = ET.fromstring(r.text)
        entries = []
        for case in root.findall(".//í•­ëª©"):
            num = case.findtext("ì‚¬ê±´ë²ˆí˜¸", "")
            title = case.findtext("íŒë¡€ëª…", "")
            gist = case.findtext("íŒê²°ìš”ì§€", "")
            entries.append(f"[{num}] {title}\nìš”ì§€: {gist}")
        return "\n\n".join(entries) if entries else "(âš ï¸ íŒë¡€ ì—†ìŒ)"
    except Exception as e:
        return f"(âš ï¸ íŒë¡€ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)})"


@app.post("/ask")
async def ask(query: Query, request: Request):
    law_text = fetch_combined_laws(["ë¶€ê°€ê°€ì¹˜ì„¸ë²•", "ë¶€ê°€ê°€ì¹˜ì„¸ë²•ì‹œí–‰ë ¹", "ë¶€ê°€ê°€ì¹˜ì„¸ë²•ì‹œí–‰ê·œì¹™"])
    prec_text = fetch_precedents_by_query(query.question, max_count=3)

    result = ask_with_law_context(query.question, law_text, precedents=prec_text, lang=query.lang)
    
    if isinstance(result, dict):
        return result

    answer, refs, summaries, mappings = result  # âœ… refs í¬í•¨

# âœ… ì´ë¯¸ ë°›ì•„ì˜¨ refsë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì!
    confidence = self_rate_answer(query.question, answer)
    _, omission_stats = extract_law_references_and_omission(answer)

    return {
        "answer": answer,
        "references": refs,
        "summaries": summaries,
        "mappings": mappings,
        "confidence": confidence,
        "omission_stats": omission_stats
    }






@app.get("/")
async def root():
    return FileResponse("static/index.html")
